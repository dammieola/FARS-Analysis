{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  FARS Analysis\n",
    "\n",
    " ## Written By Damilola OIaleye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "For each state, what day of the week has the most accidents? Use the DAY_WEEK column. Output the day and the count. For the values output the day name, where 1 is Sunday, 2 is Monday, ... and 7 is Saturday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Vermont ,  Wednessday has : 11 count(s)\n",
      "For Rhode Island ,  Thursday has : 14 count(s)\n",
      "For South Carolina ,  Saturday has : 182 count(s)\n",
      "For Virginia ,  Saturday has : 139 count(s)\n",
      "For Tennessee ,  Saturday has : 187 count(s)\n",
      "For Washington ,  Saturday has : 87 count(s)\n",
      "For South Dakota ,  Saturday has : 18 count(s)\n",
      "For Pennsylvania ,  Friday has : 186 count(s)\n",
      "For Wyoming ,  Thursday has : 19 count(s)\n",
      "For Wisconsin ,  Saturday has : 112 count(s)\n",
      "For Oregon ,  Saturday has : 76 count(s)\n",
      "For Oklahoma ,  Saturday has : 109 count(s)\n",
      "For West Virginia ,  Wednessday has : 41 count(s)\n",
      "For New Hampshire ,  Friday has : 26 count(s)\n",
      "For Minnesota ,  Saturday has : 58 count(s)\n",
      "For Michigan ,  Saturday has : 175 count(s)\n",
      "For Nevada ,  Saturday has : 56 count(s)\n",
      "For Indiana ,  Friday has : 127 count(s)\n",
      "For Maryland ,  Saturday has : 96 count(s)\n",
      "For Montana ,  Saturday has : 34 count(s)\n",
      "For Nebraska ,  Sunday has : 38 count(s)\n",
      "For Massachusetts ,  Saturday has : 61 count(s)\n",
      "For Iowa ,  Saturday has : 65 count(s)\n",
      "For Kentucky ,  Saturday has : 133 count(s)\n",
      "For New Mexico ,  Saturday has : 69 count(s)\n",
      "For Connecticut ,  Thursday has : 50 count(s)\n",
      "For Colorado ,  Friday has : 95 count(s)\n",
      "For New Jersey ,  Saturday has : 105 count(s)\n",
      "For Kansas ,  Saturday has : 63 count(s)\n",
      "For New York ,  Saturday has : 159 count(s)\n",
      "For Louisiana ,  Sunday has : 128 count(s)\n",
      "For Maine ,  Saturday has : 30 count(s)\n",
      "For North Carolina ,  Saturday has : 219 count(s)\n",
      "For Florida ,  Saturday has : 507 count(s)\n",
      "For California ,  Saturday has : 614 count(s)\n",
      "For Georgia ,  Saturday has : 258 count(s)\n",
      "For Ohio ,  Saturday has : 194 count(s)\n",
      "For Arkansas ,  Monday has : 85 count(s)\n",
      "For District of Columbia ,  Friday has : 5 count(s)\n",
      "For Delaware ,  Saturday has : 26 count(s)\n",
      "For Arizona ,  Saturday has : 150 count(s)\n",
      "For North Dakota ,  Saturday has : 22 count(s)\n",
      "For Mississippi ,  Saturday has : 118 count(s)\n",
      "For Missouri ,  Saturday has : 156 count(s)\n",
      "For Hawaii ,  Saturday has : 25 count(s)\n",
      "For Alabama ,  Saturday has : 166 count(s)\n",
      "For Illinois ,  Saturday has : 202 count(s)\n",
      "For Alaska ,  Friday has : 15 count(s)\n",
      "For Idaho ,  Friday has : 38 count(s)\n",
      "For Texas ,  Saturday has : 604 count(s)\n",
      "For Utah ,  Saturday has : 44 count(s)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "files=[f for f in os.listdir(\"FARS\")]\n",
    "filename=[f for f in os.listdir(\"FARS\") if f.startswith(\"a\")]\n",
    "days={1:\"Sunday\",2:\"Monday\",3:\"Teusday\",4:\"Wednessday\",5:\"Thursday\",6:\"Friday\",7:\"Saturday\"}\n",
    "\n",
    "states={1:\"Alabama\",2:\"Alaska\",4:\"Arizona\",5:\"Arkansas\",6:\"California\",8:\"Colorado\",9:\"Connecticut\",10:\"Delaware\",\n",
    "31:\"Nebraska\",32:\"Nevada\",33:\"New Hampshire\",34:\"New Jersey\",35:\"New Mexico\",36:\"New York\",37:\"North Carolina\",\n",
    "38:\"North Dakota\",11:\"District of Columbia\",39:\"Ohio\",12:\"Florida\",40:\"Oklahoma\",13:\"Georgia\",41:\"Oregon\",15:\"Hawaii\",\n",
    "42:\"Pennsylvania\",16:\"Idaho\",43:\"Puerto Rico\",17:\"Illinois\",44:\"Rhode Island\",18:\"Indiana\",45:\"South Carolina\",\n",
    "19:\"Iowa\",46:\"South Dakota\",20:\"Kansas\",47:\"Tennessee\",21:\"Kentucky\",48:\"Texas\",22:\"Louisiana\",49:\"Utah\",23:\"Maine\",\n",
    "50:\"Vermont\",24:\"Maryland\",52:\"Virgin Islands (since 2004)\",25:\"Massachusetts\",51:\"Virginia\",26:\"Michigan\",53:\"Washington\",\n",
    "27:\"Minnesota\",54:\"West Virginia\",28:\"Mississippi\",55:\"Wisconsin\",29:\"Missouri\",56:\"Wyoming\",30:\"Montana\"}\n",
    "\n",
    "data=[]\n",
    "for file in filename:\n",
    "    pth=os.path.join(\"FARS\",file)\n",
    "    fil=pd.read_csv(pth)\n",
    "    data.append(fil)\n",
    "totalData=pd.concat(data)    \n",
    "for i in range(len(data)):\n",
    "    col=data[i].DAY_WEEK\n",
    "    get_mode=col.mode().values[0]\n",
    "    state=data[i].STATE[2]\n",
    "    statename=states[state]\n",
    "    day=days[get_mode]\n",
    "    count=col.value_counts()[get_mode]\n",
    "    print(\"For\",statename,\", \",day,\"has :\",count,\"count(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files were read using OS library and then saved into read_data using pd.read_csv.The statecode was used to map the state to get its index, for loop was used to to get the index for the state and days of the week \n",
    "\n",
    "The mode function was used to get the highest count  from the \"DAY_WEEK\" column. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "For whole United States, i.e., all the data, what day of the week has the most accidents? \n",
    "Output the day and the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saturday has the most accident with  6104 counts\n"
     ]
    }
   ],
   "source": [
    "dayweek=[]\n",
    "for i in range(len(data)):\n",
    "    col2=data[i].DAY_WEEK\n",
    "    for i in col2:\n",
    "        dayweek.append(i)\n",
    "dayweek_lst=pd.Series(dayweek)\n",
    "get_mode2=dayweek_lst.mode().values[0]\n",
    "count2=dayweek_lst.value_counts()[get_mode2]\n",
    "\n",
    "print(days[get_mode2],\"has the most accident with \",count2,\"counts\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty list was created to store the days of the week from the \"DAY_WEEK\" column. \n",
    "It was converted into a pandas SERIES and mode was used to get the highest values series and its count. \n",
    "\n",
    "Saturday has the most accident with  6104 counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "For each state, what hour of the day has the most accidents? Output the hour and the count.\n",
    "\n",
    "* A value of 99 in the HOUR means unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Vermont , 15 hour has the most accident with 6 count\n",
      "For Rhode Island , 1 hour has the most accident with 6 count\n",
      "For South Carolina , 17 hour has the most accident with 64 count\n",
      "For Virginia , 17 hour has the most accident with 60 count\n",
      "For Tennessee , 16 hour has the most accident with 61 count\n",
      "For Washington , 15 hour has the most accident with 34 count\n",
      "For South Dakota , 14 hour has the most accident with 10 count\n",
      "For Pennsylvania , 17 hour has the most accident with 64 count\n",
      "For Wyoming , 12 hour has the most accident with 11 count\n",
      "For Wisconsin , 17 hour has the most accident with 45 count\n",
      "For Oregon , 17 hour has the most accident with 31 count\n",
      "For Oklahoma , 16 hour has the most accident with 41 count\n",
      "For West Virginia , 15 hour has the most accident with 24 count\n",
      "For New Hampshire , 16 hour has the most accident with 11 count\n",
      "For Minnesota , 15 hour has the most accident with 28 count\n",
      "For Michigan , 15 hour has the most accident with 59 count\n",
      "For Nevada , 23 hour has the most accident with 22 count\n",
      "For Indiana , 17 hour has the most accident with 50 count\n",
      "For Maryland , 22 hour has the most accident with 32 count\n",
      "For Montana , 15 hour has the most accident with 13 count\n",
      "For Nebraska , 99 hour has the most accident with 29 count\n",
      "For Massachusetts , 22 hour has the most accident with 25 count\n",
      "For Iowa , 17 hour has the most accident with 26 count\n",
      "For Kentucky , 16 hour has the most accident with 57 count\n",
      "For New Mexico , 20 hour has the most accident with 31 count\n",
      "For Connecticut , 17 hour has the most accident with 22 count\n",
      "For Colorado , 13 hour has the most accident with 38 count\n",
      "For New Jersey , 18 hour has the most accident with 42 count\n",
      "For Kansas , 16 hour has the most accident with 28 count\n",
      "For New York , 17 hour has the most accident with 59 count\n",
      "For Louisiana , 17 hour has the most accident with 48 count\n",
      "For Maine , 18 hour has the most accident with 12 count\n",
      "For North Carolina , 18 hour has the most accident with 92 count\n",
      "For Florida , 21 hour has the most accident with 208 count\n",
      "For California , 20 hour has the most accident with 210 count\n",
      "For Georgia , 18 hour has the most accident with 84 count\n",
      "For Ohio , 19 hour has the most accident with 77 count\n",
      "For Arkansas , 17 hour has the most accident with 39 count\n",
      "For District of Columbia , 2 hour has the most accident with 4 count\n",
      "For Delaware , 21 hour has the most accident with 10 count\n",
      "For Arizona , 19 hour has the most accident with 65 count\n",
      "For North Dakota , 16 hour has the most accident with 9 count\n",
      "For Mississippi , 17 hour has the most accident with 41 count\n",
      "For Missouri , 18 hour has the most accident with 57 count\n",
      "For Hawaii , 20 hour has the most accident with 10 count\n",
      "For Alabama , 16 hour has the most accident with 54 count\n",
      "For Illinois , 16 hour has the most accident with 64 count\n",
      "For Alaska , 5 hour has the most accident with 7 count\n",
      "For Idaho , 16 hour has the most accident with 17 count\n",
      "For Texas , 20 hour has the most accident with 200 count\n",
      "For Utah , 13 hour has the most accident with 26 count\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(data)):\n",
    "    col3=data[j].HOUR \n",
    "    getmode3=col3.mode().values[0]\n",
    "    state=data[j].STATE[2]\n",
    "    statename=states[state]\n",
    "    count3=col3.value_counts()[getmode3]\n",
    "    mode=col3.mode()[0]\n",
    "    print(\"For\",statename,\",\", mode,\"hour has the most accident with\",count3,\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hour and state value were stored in col3 and state respectively and mode was used to generate the maximum value count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "For whole United States, what hour of the day has the most accidents? Output the hour and the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Hours: 19 With Count: 1984\n"
     ]
    }
   ],
   "source": [
    "hours=[]\n",
    "for i in range(len(data)):\n",
    "    col4=data[i].HOUR\n",
    "    #mode=col.mode().values[0]\n",
    "    for i in col4:\n",
    "        hours.append(i)\n",
    "dayweek4=pd.Series(hours)\n",
    "getmode4=dayweek4.mode().values[0]\n",
    "count4=dayweek4.value_counts()[getmode4]\n",
    "print(\"Highest Hours:\",col4[getmode4],\"With Count:\",count4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An empty was craeted to store each. hour, and then generated the mode for both hour and count. A result of Highest Hours: 19 and Count: 1984 was generated meaning 19 th hour has the most accident "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "For each state, what is the percentage of fatal accidents involved at least one drunk driver? If the column, DRUNK_DR, has a 0, then no drunk drivers were involved. Any number larger than 0 indicates the number of drunk drivers involved in the accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage for  Vermont is:\n",
      "47.368421052631575 %\n",
      "The percentage for  Rhode Island is:\n",
      "37.5 %\n",
      "The percentage for  South Carolina is:\n",
      "35.47008547008547 %\n",
      "The percentage for  Virginia is:\n",
      "29.224376731301938 %\n",
      "The percentage for  Tennessee is:\n",
      "22.56728778467909 %\n",
      "The percentage for  Washington is:\n",
      "31.547619047619047 %\n",
      "The percentage for  South Dakota is:\n",
      "41.74757281553398 %\n",
      "The percentage for  Pennsylvania is:\n",
      "23.621323529411764 %\n",
      "The percentage for  Wyoming is:\n",
      "28.999999999999996 %\n",
      "The percentage for  Wisconsin is:\n",
      "31.985294117647058 %\n",
      "The percentage for  Oregon is:\n",
      "26.905829596412556 %\n",
      "The percentage for  Oklahoma is:\n",
      "27.564102564102566 %\n",
      "The percentage for  West Virginia is:\n",
      "27.6 %\n",
      "The percentage for  New Hampshire is:\n",
      "30.0 %\n",
      "The percentage for  Minnesota is:\n",
      "27.73109243697479 %\n",
      "The percentage for  Michigan is:\n",
      "24.79591836734694 %\n",
      "The percentage for  Nevada is:\n",
      "29.7029702970297 %\n",
      "The percentage for  Indiana is:\n",
      "17.708333333333336 %\n",
      "The percentage for  Maryland is:\n",
      "23.728813559322035 %\n",
      "The percentage for  Montana is:\n",
      "47.953216374269005 %\n",
      "The percentage for  Nebraska is:\n",
      "38.659793814432994 %\n",
      "The percentage for  Massachusetts is:\n",
      "28.690807799442897 %\n",
      "The percentage for  Iowa is:\n",
      "25.842696629213485 %\n",
      "The percentage for  Kentucky is:\n",
      "24.901703800786372 %\n",
      "The percentage for  New Mexico is:\n",
      "29.05027932960894 %\n",
      "The percentage for  Connecticut is:\n",
      "29.537366548042705 %\n",
      "The percentage for  Colorado is:\n",
      "33.691756272401435 %\n",
      "The percentage for  New Jersey is:\n",
      "21.968365553602812 %\n",
      "The percentage for  Kansas is:\n",
      "20.47244094488189 %\n",
      "The percentage for  New York is:\n",
      "17.2020725388601 %\n",
      "The percentage for  Louisiana is:\n",
      "29.545454545454547 %\n",
      "The percentage for  Maine is:\n",
      "31.125827814569533 %\n",
      "The percentage for  North Carolina is:\n",
      "28.41246290801187 %\n",
      "The percentage for  Florida is:\n",
      "21.241050119331742 %\n",
      "The percentage for  California is:\n",
      "23.443550789395292 %\n",
      "The percentage for  Georgia is:\n",
      "21.729957805907173 %\n",
      "The percentage for  Ohio is:\n",
      "33.523266856600195 %\n",
      "The percentage for  Arkansas is:\n",
      "23.36065573770492 %\n",
      "The percentage for  District of Columbia is:\n",
      "38.46153846153847 %\n",
      "The percentage for  Delaware is:\n",
      "31.03448275862069 %\n",
      "The percentage for  Arizona is:\n",
      "23.352601156069362 %\n",
      "The percentage for  North Dakota is:\n",
      "48.03921568627451 %\n",
      "The percentage for  Mississippi is:\n",
      "16.401273885350317 %\n",
      "The percentage for  Missouri is:\n",
      "27.534562211981566 %\n",
      "The percentage for  Hawaii is:\n",
      "24.770642201834864 %\n",
      "The percentage for  Alabama is:\n",
      "14.621131270010673 %\n",
      "The percentage for  Illinois is:\n",
      "26.420737786640082 %\n",
      "The percentage for  Alaska is:\n",
      "44.871794871794876 %\n",
      "The percentage for  Idaho is:\n",
      "28.448275862068968 %\n",
      "The percentage for  Texas is:\n",
      "24.713824479013795 %\n",
      "The percentage for  Utah is:\n",
      "19.69111969111969 %\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(data)):\n",
    "    mask=data[j].DRUNK_DR !=0\n",
    "    drunkAcc = data[j][mask]\n",
    "    fatal=data[j].FATALS\n",
    "    sum_count_drunk = drunkAcc.DRUNK_DR.count()\n",
    "    sum_count_accident = sum(fatal.value_counts())\n",
    "\n",
    "    percent = (sum_count_drunk/sum_count_accident)*100\n",
    "    state=data[j].STATE[2]\n",
    "    statename=states[state]\n",
    "    \n",
    "    \n",
    "    print(\"The percentage for \", statename,\"is:\")\n",
    "    print(percent, \"%\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained drunk driver element greater than 0 from the \"DRUNK_DRIVER\" column. the sum total of the drunk drivers was calculated as well as the percentage using percent = (sum_count_drunk/sum_count_accident)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6\n",
    "For whole United States, what is the percentage of fatal accidents involved at least one drunk driver?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of fatal accident for the whole state is: 25.320131246551874 %\n"
     ]
    }
   ],
   "source": [
    "drunkDr = []\n",
    "fatalAccident = []\n",
    "for j in range(len(data)):\n",
    "    mask=data[j].DRUNK_DR !=0\n",
    "    drunkAcc = data[j][mask]\n",
    "    fatal=data[j].FATALS\n",
    "    drunkSum = drunkAcc.DRUNK_DR.count()\n",
    "    accidentSum = sum(fatal.value_counts())\n",
    "    \n",
    "    drunkDr.append(drunkSum)\n",
    "    fatalAccident.append(accidentSum)\n",
    "\n",
    "accident_percent = (sum(drunkDr)/sum(fatalAccident)*100)\n",
    "print(\"The percentage of fatal accident for the whole state is:\" , accident_percent,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!=0 was used to obtain the value of drunk driver not equal to 0,drunkDr contains the sum of drunk driver greater than 0 and fatalAccident contains the sum of all fatal accident.\n",
    "\n",
    "accident_percent = (sum(drunkDr)/sum(fatalAccident)*100) wasn used to calculate the percentage\n",
    "\n",
    "25.320131246551874 % was obtained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "For whole United States, how many fatalities were caused by each type of collision? Use the MAN_COLL column. The values in the column are below.\n",
    "\n",
    "* 0\tNot Collision with Motor Vehicle in Transport\n",
    "* 1\tFront-to-Rear\n",
    "* 2\tFront-to-Front\n",
    "* 6\tAngle\n",
    "* 7\tSideswipe – Same Direction\n",
    "* 8\tSideswipe – Opposite Direction\n",
    "* 9\tRear-to-Side\n",
    "* 10 Rear-to-Rear\n",
    "* 11 Other (End-Swipes and Others)\n",
    "* 98 Not Reported\n",
    "* 99 Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Collision with Motor Vehicle in Transport caused 21296 fatalities\n",
      "Front-to-Rear caused 2350 fatalities\n",
      "Front-to-Front caused 3511 fatalities\n",
      "Angle caused  6122 fatalities\n",
      "Sideswipe – Same Direction caused 519 fatalities\n",
      "Sideswipe – Opposite Direction caused 421 fatalities\n",
      "Rear-to-Side caused 32 fatalities\n",
      "Rear-to-Rear caused 2 fatalities\n",
      "Other (End-Swipes and Others) caused 86 fatalities\n",
      "Not Reported caused 23 fatalities\n",
      "Unknown caused 77 fatalities\n"
     ]
    }
   ],
   "source": [
    "colision_count = totalData[\"MAN_COLL\"].value_counts()\n",
    "print(\"Not Collision with Motor Vehicle in Transport caused\", colision_count[0],\"fatalities\")\n",
    "print(\"Front-to-Rear caused\", colision_count[1],\"fatalities\")\n",
    "print(\"Front-to-Front caused\", colision_count[2],\"fatalities\")\n",
    "print(\"Angle caused \", colision_count[6],\"fatalities\")\n",
    "print(\"Sideswipe – Same Direction caused\", colision_count[7],\"fatalities\")\n",
    "print(\"Sideswipe – Opposite Direction caused\", colision_count[8],\"fatalities\")\n",
    "print(\"Rear-to-Side caused\", colision_count[9],\"fatalities\")\n",
    "print(\"Rear-to-Rear caused\", colision_count[10],\"fatalities\")\n",
    "print(\"Other (End-Swipes and Others) caused\", colision_count[11],\"fatalities\")\n",
    "print(\"Not Reported caused\", colision_count[98],\"fatalities\")\n",
    "print(\"Unknown caused\", colision_count[99],\"fatalities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "colision_count was used to store the count of collision value from \"MAN_COLL\" column. \n",
    "\n",
    "Each count value was used to map the code for the collision type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8\n",
    "For each state, what is its fatal accident rate per 10,000 people? To calculate this, count the number of accidents in a state, divide by the state's 2016 population estimate from the nst-est2017-alldata.csv Census data file, and then multiply by 10000. Output the states' rates in order from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('California', 44.43132666620784),\n",
       " ('Alabama', 15.031587188018365),\n",
       " ('Pennsylvania', 11.420198216013889),\n",
       " ('New York', 7.228383201686872),\n",
       " ('Texas', 5.901695797808976),\n",
       " ('Colorado', 5.372327315299772),\n",
       " ('Utah', 4.428031662990887),\n",
       " ('Oklahoma', 4.367658885841016),\n",
       " ('Michigan', 3.1301213816355777),\n",
       " ('New Jersey', 2.982800928704767),\n",
       " ('Florida', 2.887752101103027),\n",
       " ('Ohio', 2.6853976339428143),\n",
       " ('Virginia', 2.416145204303148),\n",
       " ('Arizona', 1.744014200509615),\n",
       " ('Indiana', 1.7312453492505713),\n",
       " ('West Virginia', 1.4880722084062985),\n",
       " ('Wyoming', 1.461270487012228),\n",
       " ('Kentucky', 1.3809829775296152),\n",
       " ('South Carolina', 1.3548248700685317),\n",
       " ('Kansas', 1.2962472790714923),\n",
       " ('Montana', 1.2854900498559652),\n",
       " ('Idaho', 1.2687045050493893),\n",
       " ('Georgia', 1.2234832378494436),\n",
       " ('New Mexico', 1.1991632654086617),\n",
       " ('Arkansas', 1.1943252906456674),\n",
       " ('Illinois', 1.1920070165597465),\n",
       " ('North Dakota', 1.1839237088847672),\n",
       " ('Delaware', 1.0968582575461012),\n",
       " ('Nevada', 1.042049625635934),\n",
       " ('Maryland', 1.0072219091251104),\n",
       " ('Mississippi', 0.944445547300179),\n",
       " ('Washington', 0.9113751004727758),\n",
       " ('Louisiana', 0.7841026746811465),\n",
       " ('Maine', 0.7240706002401421),\n",
       " ('North Carolina', 0.6795626963636238),\n",
       " ('Rhode Island', 0.6473172744706158),\n",
       " ('Minnesota', 0.5381363028408019),\n",
       " ('Massachusetts', 0.5261059178709094),\n",
       " ('Connecticut', 0.46132306799212497),\n",
       " ('Oregon', 0.4324378831099071),\n",
       " ('Iowa', 0.3583852329176836),\n",
       " ('Hawaii', 0.35804371483821845),\n",
       " ('Nebraska', 0.32200495555667685),\n",
       " ('Missouri', 0.31105690470714387),\n",
       " ('South Dakota', 0.287093209130679),\n",
       " ('Wisconsin', 0.263354225617792),\n",
       " ('Tennessee', 0.24582356952312975),\n",
       " ('Vermont', 0.11727079987943738),\n",
       " ('Alaska', 0.10712911283085384),\n",
       " ('New Hampshire', 0.1012798185314956),\n",
       " ('District of Columbia', 0.020333015695133017)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=[f for f in os.listdir(\"FARS\")]\n",
    "filename2=[f for f in os.listdir(\"FARS\") if f.startswith(\"n\")]\n",
    "PopLst = []\n",
    "for file in files:\n",
    "    if file.startswith(\"n\"):\n",
    "        pathname = os.path.join(\"FARS\", file)\n",
    "        frame = pd.read_csv(pathname)\n",
    "        popestimate = frame[\"POPESTIMATE2016\"]\n",
    "        b = popestimate[5:57]\n",
    "for item in b:  \n",
    "    PopLst.append(item)\n",
    "stateFatal_dict={}\n",
    "print(len(data))\n",
    "for j in range(len(data)):  \n",
    "    fatal=data[j].FATALS\n",
    "    sum_count_accident =sum(fatal.value_counts())\n",
    "    fatal_state_acc = (sum_count_accident/PopLst[j])*10000\n",
    "    state=data[j].STATE[2]\n",
    "    statename=states[state]\n",
    "    stateFatal_dict[statename] = fatal_state_acc\n",
    "\n",
    "from operator import itemgetter\n",
    "sortedlist = sorted(stateFatal_dict.items(), key = itemgetter(1), reverse = True)\n",
    "sortedlist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the os to load the data, and then created an empty stateFatal_dict to store fatal accident rate per 10,000 people  using the formular fatal_state_acc = (sum_count_accident/PopLst[j])*10000 and then finally used item getter to get the key value from the dic created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9\n",
    "For each state, what is the rate of fatal accidents caused by drunk driving per 10,000 people? To calculate this, count the number of accidents in which a drunk driver was involved, divide by the state's 2016 population estimate from the nst-est2017-alldata.csv Census data file, and then multiply by 10000. Output the states' rates in order from highest to lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('California', 10.41628063339457),\n",
       " ('Pennsylvania', 2.697601968304751),\n",
       " ('Alabama', 2.1977880947262713),\n",
       " ('Colorado', 1.8100314252264464),\n",
       " ('Texas', 1.4585347407558433),\n",
       " ('New York', 1.243431721740954),\n",
       " ('Oklahoma', 1.203905974943357),\n",
       " ('Ohio', 0.9002330149874771),\n",
       " ('Utah', 0.8719290147202134),\n",
       " ('Michigan', 0.77614234258923),\n",
       " ('Virginia', 0.7061033768808369),\n",
       " ('New Jersey', 0.6552726117541228),\n",
       " ('Montana', 0.6164338250771294),\n",
       " ('Florida', 0.6133888711173494),\n",
       " ('North Dakota', 0.568747664072094),\n",
       " ('South Carolina', 0.4805575393832826),\n",
       " ('Wyoming', 0.4237684412335461),\n",
       " ('West Virginia', 0.41070792952013835),\n",
       " ('Arizona', 0.40727268035022224),\n",
       " ('Idaho', 0.3609245574709469),\n",
       " ('New Mexico', 0.34836027821927606),\n",
       " ('Kentucky', 0.34388829060370496),\n",
       " ('Delaware', 0.3404042868246521),\n",
       " ('Illinois', 0.314937048243602),\n",
       " ('Nevada', 0.3095196907829507),\n",
       " ('Indiana', 0.30657469726312203),\n",
       " ('Washington', 0.2875171447920067),\n",
       " ('Arkansas', 0.279002219536078),\n",
       " ('Georgia', 0.265862391347031),\n",
       " ('Kansas', 0.2653734587075496),\n",
       " ('Rhode Island', 0.24274397792648095),\n",
       " ('Maryland', 0.23900180894494144),\n",
       " ('Louisiana', 0.23166669933761144),\n",
       " ('Maine', 0.22537296828666675),\n",
       " ('North Carolina', 0.19308049904099991),\n",
       " ('Mississippi', 0.15490110091069814),\n",
       " ('Massachusetts', 0.15094403771783751),\n",
       " ('Minnesota', 0.14923107557770138),\n",
       " ('Connecticut', 0.13626268556351023),\n",
       " ('Nebraska', 0.12448645189046786),\n",
       " ('South Dakota', 0.11985444653028346),\n",
       " ('Oregon', 0.11635099993988532),\n",
       " ('Iowa', 0.09261640850681711),\n",
       " ('Hawaii', 0.08868972752873301),\n",
       " ('Missouri', 0.08564815694125275),\n",
       " ('Wisconsin', 0.08423462363510259),\n",
       " ('Vermont', 0.05554932625868087),\n",
       " ('Tennessee', 0.05547571237685536),\n",
       " ('Alaska', 0.04807075575743442),\n",
       " ('New Hampshire', 0.03038394555944868),\n",
       " ('District of Columbia', 0.007820390651974238)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=[f for f in os.listdir(\"FARS\")]\n",
    "filename2=[f for f in os.listdir(\"FARS\") if f.startswith(\"n\")]\n",
    "PopLst2 = []\n",
    "for file in files:\n",
    "    if file.startswith(\"n\"):\n",
    "        pathname = os.path.join(\"FARS\", file)\n",
    "        frame = pd.read_csv(pathname)\n",
    "        popestimate = frame[\"POPESTIMATE2016\"]\n",
    "        b = popestimate[5:57]\n",
    "for item in b:  \n",
    "    PopLst2.append(item)\n",
    "stateFatal_dict={}\n",
    "for j in range(len(data)): \n",
    "    mask=data[j].DRUNK_DR !=0\n",
    "    drunkAcc = data[j][mask]\n",
    "    sum_count_drunk = drunkAcc.DRUNK_DR.count()\n",
    "                \n",
    "    fatal_state_acc = (sum_count_drunk/PopLst2[j])*10000\n",
    "    state=data[j].STATE[2]\n",
    "    statename=states[state]\n",
    "    stateFatal_dict[statename] = fatal_state_acc\n",
    "\n",
    "from operator import itemgetter\n",
    "sortedlist = sorted(stateFatal_dict.items(), key = itemgetter(1), reverse = True)\n",
    "sortedlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the os to load the data, and then created an empty stateFatal_dict to store fatal accident rate per 10,000 people. \n",
    "I used data[j].DRUNK_DR !=0 to get the value o\n",
    "using the formular fatal_state_acc = (sum_count_accident/PopLst[j])*10000 and then finally used item getter to get the key value from the dic created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('California', 10.41628063339457),\n",
       " ('Pennsylvania', 2.697601968304751),\n",
       " ('Alabama', 2.1977880947262713),\n",
       " ('Colorado', 1.8100314252264464),\n",
       " ('Texas', 1.4585347407558433),\n",
       " ('New York', 1.243431721740954),\n",
       " ('Oklahoma', 1.203905974943357),\n",
       " ('Ohio', 0.9002330149874771),\n",
       " ('Utah', 0.8719290147202134),\n",
       " ('Michigan', 0.77614234258923),\n",
       " ('Virginia', 0.7061033768808369),\n",
       " ('New Jersey', 0.6552726117541228),\n",
       " ('Montana', 0.6164338250771294),\n",
       " ('Florida', 0.6133888711173494),\n",
       " ('North Dakota', 0.568747664072094),\n",
       " ('South Carolina', 0.4805575393832826),\n",
       " ('Wyoming', 0.4237684412335461),\n",
       " ('West Virginia', 0.41070792952013835),\n",
       " ('Arizona', 0.40727268035022224),\n",
       " ('Idaho', 0.3609245574709469),\n",
       " ('New Mexico', 0.34836027821927606),\n",
       " ('Kentucky', 0.34388829060370496),\n",
       " ('Delaware', 0.3404042868246521),\n",
       " ('Illinois', 0.314937048243602),\n",
       " ('Nevada', 0.3095196907829507),\n",
       " ('Indiana', 0.30657469726312203),\n",
       " ('Washington', 0.2875171447920067),\n",
       " ('Arkansas', 0.279002219536078),\n",
       " ('Georgia', 0.265862391347031),\n",
       " ('Kansas', 0.2653734587075496),\n",
       " ('Rhode Island', 0.24274397792648095),\n",
       " ('Maryland', 0.23900180894494144),\n",
       " ('Louisiana', 0.23166669933761144),\n",
       " ('Maine', 0.22537296828666675),\n",
       " ('North Carolina', 0.19308049904099991),\n",
       " ('Mississippi', 0.15490110091069814),\n",
       " ('Massachusetts', 0.15094403771783751),\n",
       " ('Minnesota', 0.14923107557770138),\n",
       " ('Connecticut', 0.13626268556351023),\n",
       " ('Nebraska', 0.12448645189046786),\n",
       " ('South Dakota', 0.11985444653028346),\n",
       " ('Oregon', 0.11635099993988532),\n",
       " ('Iowa', 0.09261640850681711),\n",
       " ('Hawaii', 0.08868972752873301),\n",
       " ('Missouri', 0.08564815694125275),\n",
       " ('Wisconsin', 0.08423462363510259),\n",
       " ('Vermont', 0.05554932625868087),\n",
       " ('Tennessee', 0.05547571237685536),\n",
       " ('Alaska', 0.04807075575743442),\n",
       " ('New Hampshire', 0.03038394555944868),\n",
       " ('District of Columbia', 0.007820390651974238)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files=[f for f in os.listdir(\"FARS\")]\n",
    "#filename2=[f for f in os.listdir(\"FARS\") if f.startswith(\"n\")]\n",
    "PopLst2 = []\n",
    "for file in files:\n",
    "    if file.startswith(\"n\"):\n",
    "        pathname = os.path.join(\"FARS\", file)\n",
    "        frame = pd.read_csv(pathname)\n",
    "        popestimate = frame[\"POPESTIMATE2016\"]\n",
    "        b = popestimate[5:57]\n",
    "for item in b:  \n",
    "    PopLst2.append(item)\n",
    "stateFatal_dict={}\n",
    "for j in range(len(data)): \n",
    "    mask=data[j].DRUNK_DR\n",
    "    mask1=[]\n",
    "    for w in mask:\n",
    "        if w>0:\n",
    "            mask1.append(w)\n",
    "    #drunkAcc = data[j][mask]\n",
    "    #sum_count_drunk = drunkAcc.DRUNK_DR.count()\n",
    "                \n",
    "    fatal_state_acc = (len(mask1)/PopLst2[j])*10000\n",
    "    state=data[j].STATE[2]\n",
    "    statename=states[state]\n",
    "    stateFatal_dict[statename] = fatal_state_acc\n",
    "\n",
    "from operator import itemgetter\n",
    "sortedlist = sorted(stateFatal_dict.items(), key = itemgetter(1), reverse = True)\n",
    "sortedlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
